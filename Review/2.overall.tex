\section{Main Modifications introduced in  \scipion: Streaming and Metaprotocols}
\label{overall}

In the following we describe the most important modifications made to \scipion to facilitate its deployment and execution in centralized facilities.

\subsection{Stream Processing}

Stream processing, i.e., computing on data directly as they are produced or received, is the main change introduced in \scipion. 
In this way, a new level of parallelization has been reached since the  data generated by the microscope continuously flows through a chain of protocols. For example, as movies are imported to the system they are aligned and their CTF is estimated. In \scipion version 1.2, users may find  the first steps in the image processing workflow adapted to streaming, including movie alignment,  CTF estimation and particle picking and extraction. In the developers version, several 2D classification algorithms are being adapted for this new way of processing.

%\scipion is a multilayered application, the first layer handles the interaction with the user (\emph{presentation layer}), the second saves and retrieves the data used by the application  (\emph{data layer}) and finally, the third layer (\emph{business layer}) process the data following the user instructions.  
\scipion stream implementation make extensive use of threads. %A thread is the smallest unit of processing that can be scheduled by an operating system. 
Using threads, a programmer can effectively create two or more tasks that run at the same time and share the protocol resources (e.g. memory). 
%is based on periodic updates of the protocol input and output data during the image processing. 
%Each protocol execution in \scipion is an independent process that can create processing threads. 
Each protocol that works in streaming mode has one of its threads monitoring input and updating output  data while other threads take care of the data processing. This clear separation between data access and data processing marks an important difference between running a script or using \scipion, since it facilitates a form of computing in which several jobs are executed  concurrently, instead of sequentially. Moreover, \scipion workflow engine allows users to modify the workflow on the fly without modifying a single line of code.
%In practice, the latter follows  a more general and extensible approach that allows users to modify the workflow on the fly without modifying a single code line. %Moreover, it also allows to quickly develop new workflows .

%Since allow to a form of computing in which several computations are executed during overlapping time periods—concurrently—instead of sequentially

%** JMRT: The following line is a more specify explanation, while the previous paragraph was more general
%The modification will not interfere with the already executed steps and may take advantage from all already computed data. By default \scipion will automatically stop after 24 hours with no microscope activity, but you may  continue the acquisition after a stop by pressing the continue button, there is no need to restart from the beginning. 

%\scipionbox uses the infrastructure provided by the Scipion project [Ref if not given already] that takes care of the creation and execution of workflows. These workflows may be imported from a set of predefined ones or created by the final users even if they have no programing skills.

%A typical \scipion workflow starts importing the microscope data, then the  beam-induced movement is corrected. For this task, \scipion allows you to choose between five different algorithms from three different labs (an exhaustive list containing the approximately 200 algorithms accessible through \scipion and ranked by usability is available at \url{http://calm-shelf-73264.herokuapp.com/report_protocols/protocolTable/}). This multiplicity of possibilities is available at each different processing step although, if found overwhelming, may be ignored by choosing one of the default prepackaged workflows.   

\subsection{Metaprotocols}
Since the \scipion original publication we have developed many \emph{metaprotocols}, that is, 
protocols that either check the progress of other protocols or compare the results of equivalent protocols.

The first type of metaprotocols are called \emph{monitors} and are used to produce live analysis plots, generate reports or raise alerts when some problems are detected. A monitor example is the \protocol{CTF-monitor}, that checks the computed defocus values for each micrograph as they are generated. \protocol{CTF-monitor} may raise an alert if the defocus values are above or below certain thresholds and continuously generate HTML files so that users and staff may easily follow the data acquisition and processing either in-house or remotely. An example of these reports may be seen at \url{http://scipion.cnb.csic.es/scipionbox/lastHTMLReport/}% [**ROB NOTE: select a nice one an complete URL, I need to ask to javi chichon]%At the project's end, a review of the processing history is produced. [** URL to report example?]
%This feature was very important since we knew that difference facilities will have different needs and criteria to be fulfilled.

The second set of metaprotocols are grouped under the name \emph{consensus}. For a given logical step (for example, particle picking) these protocols check 
the consistency of the output datasets obtained from the same input data using different algorithms. Continuing with the particle picking example, \protocol{consensus picking} will compare, at a given instant, the particles selected for each one of the executed particle-picking algorithms and produce as output a particle set containing those particles selected by most of the algorithms.

We would like to finish this section stressing that despite the modifications introduced to \scipion data and process model, the framework is backward compatible and keeps providing full data provenance. In other words, \scipion provides detailed information about the origin of the data  and the process to generate it.


%for any object created by a  protocol, \scipion always annotate how this object has been generated by detailing: the steps, input data and parameters used in the computation. Data provenance guaranties reproducibility and traceability. %Since provenance is solved by Scipion and not Scipionbox we will not discuss here how it is been achieved. We just note that, before choosing which data has to be stored, it is necessary to define how these data have to be structured so that they can be later recovered and understood . %This abstract modeling of the data also simplifies the software interoperability offered by Scipion.


%Standardization
%User has access to all parameters used by algorithms (she may ignore them)
%Project can be imported in scipion without further ado.
%Gui vs programatico
%Export options?

\section{Image Processing Workflows}

\scipion is a flexible framework that allows to create different workflows by choosing among many algorithms at each step. Although the best workflow for each case will depend on specific requirements of specimens, microscopes or facilities, we  describe the pipeline offered by default at the \emph{National Center for Biotechnology} (\cnb) cryoEM Facility as use case to clarify \scipion capabilities.

The workflow starts two independent protocols in parallel. The first protocol estimates the camera gain at each pixel for a few  movies \citep{sorzano2018}. % In the CNB setup the microscope camera is calibrated and internally performs the gain correction before writing the movies so the estimated gain image should be almost constant and equal to 1. 
The output of this protocol serves as verification of the validity of the experimental gain image for the whole data set. The second protocol performs direct detector movie alignment. Currently, \scipion offers  five  methods for movie alignment: motioncorr \citep{Li2015}, motioncor2 \citep{Zheng2016:motioncor2}, correlation (an unpublished CPU version that implements in Xmipp a global alignment method and solves it similarly to motioncorr but using robust statistics), unblur \citep{Grant2015:unblur} and optical flow \citep{Abrishami2015:optical-flow}. Then the CTFs of the resulting micrographs are calculated. Scipion provides three CTF estimation methods:
CTFFIND4 (Rohou and Grigorieff, 2015), gCTF (Zhang, 2016) and Xmipp CTF estimation (Sorzano et al., 2007; Vargas et al., 2013). At this point the user may compute the CTFs using several algorithms and compare them with the protocol \protocol{CTF consensus} that reports up to which frequency two estimations of the same micrograph are equivalent. Further automatic filtering based on CTF is available through the protocol \protocol{CTF filtering} that selects micrographs based on the astigmatism, resolution and defocus. %Another criteria for CTF selection is iciness, that is,  the ratio of the intensity in the resolution band between 3.5 and 3.9 \AA, and between 6 and 30 \AA, which gives a good estimate of the ice crystal content of the vitreous specimen.

Up to this point the image processing pipeline is quite solid and may be executed in streaming without user intervention. The next step is to select (pick) particles. We have recently adapted eight particle picking methods in \scipion  for streaming (see at \url{https://github.com/I2PC/scipion/wiki/Integrated-Protocols#particles} an exhaustive list). In this way,  particles may be selected as soon as any new micrograph is available. Some picking algorithms require a training step in which either user intervention or information from a previous selection is needed. The streaming functionality is separated from the picking logic, so if in the future a new algorithm is added, it will work in streaming without extra effort from the algorithm developer. For those users that execute several picking algorithms, the protocol \protocol{picking consensus} may be useful. \protocol{picking consensus}  calculates the agreement between different particle-picking algorithms and produces a list with the particles selected by most of them.

Two new streaming protocols are under development and will join the described  pipeline in a near future. The first one will perform 2D classification and the second one will create an initial 3D map based on these classes. A first version of these protocols is available in the \scipion developers version.

As commented in Section \ref{overall}, to monitor, chart and create alerts  we have developed a set of metaprotocols. By default, \protocol{system}, \protocol{CTF} and \protocol{report monitors} are executed. \protocol{System monitor} reports on  CPU and GPU usage, memory consumption, and disk I/O. \protocol{CTF monitor} plots the CTF defocus and astigmatism  and it will raise an alarm if these parameters are not within a given range. Finally, the \protocol{report} protocol pushes all the created plots and summaries to a web server. This information can be accessed by users who are not physically in the microscope room (a live example report is available at \url{http://nolan.cnb.csic.es/scipionbox/lastHTMLReport/}).

The proposed pipeline is very flexible and can be easily modified by each user. At the CNB (and collaborating institutions) we collect protocol usage statistics within \scipion and sort the different algorithms by popularity.  This information is available at  \url{http://scipion.i2pc.es/report_protocols/protocolTable/} and may help users to select between the different algorithms.


