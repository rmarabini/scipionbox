\section{Main Modifications introduced in  \scipion: Streaming, Monitors and Consensus}
\label{overall}

In the following we describe the main modifications introduced in the original \scipion version in order to facilitate its deployment in centralized facilities. 

The main change introduced in \scipion is \emph{stream processing}. Stream processing has been designed to analyze and react on real-time so that enables analysis of data as it is produced.
In this way a new level of parallelization has been reached since the  data generated by the microscope continuously flows through a chain of protocols. For example, as movies are imported to the system they are aligned and their CTF is estimated. In \scipion stable version users may find  the first steps in the image processing adapted to stream. These steps include: movie alignment, CTF estimation and particle picking. In \scipion developers version  several 2D classification algorithms are available.

\scipion stream implementation is based on periodic updates of the protocol input and output data during the image processing. Since \scipion runs on threads, it is possible to devote one thread to update these information while the rest of the CPU power is devoted to run the different protocols. The use of threads marks an important difference between running a script or using \scipion, since  each module is run independently creating a very flexible processing framework. For example, do you want to add a new protocol in your workflow while it is running? No problem, do it. \scipion allows users to modify  workflows on the fly without modifying a single code line. The modification will not interfere with the already executed steps and may take advantage from all already computed data. Did something go wrong and the microscope stopped? By default \scipion will stop after 24 hours with no microscope activity, but if you wish to continue your acquisition after a stop just press the continue button, there is no need to restart from the beginning. 

%\scipionbox uses the infrastructure provided by the Scipion project [Ref if not given already] that takes care of the creation and execution of workflows. These workflows may be imported from a set of predefined ones or created by the final users even if they have no programing skills.

%A typical \scipion workflow starts importing the microscope data, then the  beam-induced movement is corrected. For this task, \scipion allows you to choose between five different algorithms from three different labs (an exhaustive list containing the approximately 200 algorithms accessible through \scipion and ranked by usability is available at \url{http://calm-shelf-73264.herokuapp.com/report_protocols/protocolTable/}). This multiplicity of possibilities is available at each different processing step although, if found overwhelming, may be ignored by choosing one of the default prepackaged workflows.   

Since \scipion original publication we have developed many \emph{metaprotocols}, that is, 
protocols that either check the progress of other protocols or compare the results of equivalent protocols.

The first type of metaprotocols are called \emph{monitors} and are used to produce live analysis plots, generate reports or raise alerts when some problems are detected. A monitor example is the \emph{CTF-monitor}, that checks the computed defocus values for
each micrograph as they are generated. CTF-monitor may raise an alert if the defocus values are above or below certain thresholds and continuously generate HTML files so that users and staff may easily follow the data acquisition and processing in-house or remotely. An example of this reports may be seen at \url{http://nolan.cnb.csic.es/scipionbox/} [**ROB NOTE: select a nice one an complete URL]%At the project's end, a review of the processing history is produced. [** URL to report example?]
%This feature was very important since we knew that difference facilities will have different needs and criteria to be fulfilled.

The second set of metaprotocols are grouped under the name \emph{consensus}. For a given logical step (for example, particle picking) these protocols check if the datasets obtained from the same input data using different algorithm are consistent. Continuing with the particle picking example, \emph{consensus picking} will compare the particles selected for each one of the executed particle-picking algorithms and produce as output a particle set containing those particles selected by most of the algorithms.


Last but not least \scipion provides full data provenance. Data provenance is an important form of metadata that describes how a particular data set was generated by detailing: the steps, input data and parameters used in the computation. Data provenance guaranties reproducibility and traceability. %Since provenance is solved by Scipion and not Scipionbox we will not discuss here how it is been achieved. We just note that, before choosing which data has to be stored, it is necessary to define how these data have to be structured so that they can be later recovered and understood . %This abstract modeling of the data also simplifies the software interoperability offered by Scipion.


%Standardization
%User has access to all parameters used by algorithms (she may ignore them)
%Project can be imported in scipion without further ado.
%Gui vs programatico
%Export options?


 

