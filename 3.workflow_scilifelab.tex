
\subsection{Swedish National CryoEM Facility}

The Swedish National Cryo-EM Facility offers access to state-of-the-art equipment and expertise 
in single particle cryo-EM and cryo electron tomography (cryo-ET). The Facility has two nodes: at SciLifeLab 
in Stockholm and at Umeå University. SciLifeLab in Stockholm offers single-particle service with a 
Talos Arctica for sample optimisation and a Titan Krios for high-resolution data collection. 
The Umeå node is expected to become operational during 2018, and will offer cryo-ET with a 
Titan Krios and a Scios DualBeam SEM.

The facilities can be accessed by Swedish researchers through a peer-reviewed routine. Applications can be 
submitted through an Application Portal [**reference???] and will be evaluated once every three months based on their 
scientific merit and technical feasibility by a national Project Evaluation Committee. On the other side, 
some time of the facility is reserved for internal research groups at Stockholm University. Internally, the allocation
of the microscope (and other instruments) time is managed by a Booking System [** name of the booking system and reference???]. 


At the beginning of 2016, the Cryo-EM facility at SciLifeLab became one of the early adopters of \scipion 
for on the fly data processing. Before, there were some home-made scripts to perform motion correction (with motioncor)
and CTF estimation (with Gctf). The microscope operators recognized the importance of  
a more general framework with the possibility to be extended with new programs. Another strong point was the 
the availability of graphical tools for data analysis and quick feedback about the data collection. Initially, the 
same setup script from the CNB was used, but it had some limitations for this more complex setup with more 
requirements. In the following sections we will briefly describe the computational infrastructure at the
SciLifeLab node and the implementation of a Session Wizard to automate the initial setup while fetching 
information from other sources external to Scipion. 


\subsubsection{Infrastructure}
At the heart of the SciLifeLab computational infrastructure is a storage and pre-processing server (the
staging server). This machine has roughly 200 TB of storage (4 ZFS RAIDZ2 pools
with 11 HDDs each), 2 NVIDIA GeForce GTX 1070 GPUs, 2 Intel Xeon E5-2630v4 CPUs
(10 cores, 2.2 GHz, HT), 384 GB RAM, and a dual-port 10 GbE network card. The
storage pool is exported via NFS and Samba, so the microscope computers can
write data there directly and other machines can access it.

Unfortunately the K2 computer writes data to a local SSD RAID, the Falcon-III to
a dedicated storage server (the offload server), in order to avoid interruption
of data collection due to network issues. So when users start data collection,
they start a script that continously moves the produced data to the staging
server.

By having all data on the staging server, in an organized folder structure, we
can run pre-processing directly on the server. If processing is started soon
after data collection the incoming file data should still be in RAM and does not
have to be read from disk, which is important with performance in mind. Users
can copy their data to external USB drives from two workstations in the
microscope room, that have access to the storage pool via NFS.
There is also a dedicated download server with access to the NFS export,
reachable from the Internet. Here users can log in to a restricted shell that
allows downloads via rsync (over SSH) or SFTP. 

All these computers are conntected to a 10 GbE network switch. This is a private
network without external access. The only machine accessible from the Internet
is the data download server, which has a dual-port 10 GbE network adapter (one
used for the private network, one for the external network). Both the K2
computer and the Falcon-III offload server had one unused 10GbE interface that
could be used to connect them to our private network, without having to
interfere with the default setup.

\subsubsection{Session Wizard}

The initial attempt to ease the setup of \scipion projects for stream processing was based  
on the original script developed at the CNB. But it was difficult to reuse the existing code due to a different folder
structure and, more important, a different logic about users and microscopes management. To address the new set
of requirements, a new ``wizard'' is being developed at SciLifeLab and can be found in the following open source repository: 
\url{https://github.com/delarosatrevin/scipion-session}

For this new wizard, a basic data model was designed representing the current processing and data 
organization at SciLifeLab. The model is composed by the following entities:

\begin{itemize}
\setlength\itemsep{0em}
 \item \textit{User}: represents all persons that can book microscope time or are registered in the Application Portal 
 related to national projects.
 \item \textit{Reservation}:  is a resource (e.g, Krios, Talos, Vitrobot, etc) booking for a given period of time.
 \item \textit{Order}:  is a given national project with an unique identifier in the Application Portal
 \item \textit{Project}:  can be a either a national project (related to a given Order) or an internal project.
 \item \textit{Session}:  stores information about the usage of the micrograph for a given day.
\end{itemize}

When an user starts a data collection, the wizard is also executed using the command \textit{session-titan} 
(or \textit{session-talos}). The wizard will fetch the reservations for this day using a webservices API provided by 
the Booking System and will check wich user is operating the microscope. From the reservation information, 
the wizard will also detect if it is an internal project or a national facility project. If the latter,
more information will be retrieved from the Applicacion Portal (such as principal investigator, project code, 
contact person or invoice address). After gathering all this information, the wizard setup the Scipion project
for streaming processing. For example, the movies-import protocol will already point to the location where
the files will be written for this session. Moreover, taking into account which microscope-camera is being 
used, the files pattern can be inferred. 

The current implementation of the wizard stores each session in a simple database file. This database, together
with extra information from the Booking System and the Appplication Portal, is used to generate reports for 
a given period with the associated invoices. The generation of a session report is under development, that 
will provide a summary and useful information for users to access the acquired data. The existing data model 
represents the specify usage at the SciLifeLab facility and there are not inmediate plans to make it more 
general and easy to reuse. Nonetheless, the model is quite simple and should to be difficult to modify it to fit 
other requirements. 


