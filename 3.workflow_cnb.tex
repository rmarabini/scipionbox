\subsection{CNB Facility}
%Here there are Scipion general features and CNB specific. Move the general to the Processing with Scipion section.

At the beginning CNB setup was a quite straight forward one, movies where stored in the  same machine that ran \Scipion and processed data was saved to external USB hard disks by the same machine. The situation changed when the new Falcon-III camera  

From a network point of view there are three different levels of accessibility: (1) a private network that cannot be accessed by regular users, (2) the CNB LAN (local area network)  that can be accessed by any user which works inside the hosting  institution and (3) finally, there is a single computer that may be accessed from outside the institution and therefore, it can see the WAN (wide area network).

Data sets are recorded using EPU. The microscope control system has a 70 TB NAS (Network-attached storage) unit for saving movies as they are obtained (we will refer to this NAS as microscope-NAS). This storage unit is shared through a Samba share and connected to the private network using a 10Gb connexion. \scipion is executed on a Linux server which has two 1Gb NICs (network interface controllers) that connect it to the private and the LAN networks (we will refer to this machine as \scipionbox). This machine has 32 CPUs at 2.40GHz, 62 Gb of RAM memory and 2 \textit{Quadro M4000} GPUs. Finally, a second NAS with 4 1Gb NICs is linked to the private, LAN and WAN networks (we will refer to this second NAS as output-NAS).

The data flow is a follows: (a) the microscope system stores movies in the microscope-NAS, (b) when executing alignment-movie protocols \scipionbox will temporary read the movies from 
the microscope-NAS but will not store them locally, (c) each hour, output-NAS will connect to \scipionbox and copy or update the last \scipion project, (d) at the same time output-NAS may be either executing a script to incrementally backup the \scipion project and the movies to a USB disk or serve this information through the Internet and (e) in parallel \scipionbox transfers to  output-NAS different html reports that may be checked by users or staff with a HTML browser.
[** create figure]

Discuss transfer rates
Discuss typical workflow

The first decision a user must face is the backup policy. The recommended strategy is either to attach an external hard disk to the server or provide a remote storage location. \scipionbox will transfer both raw and processed data as soon as available. In this way, access to the Linux server seldom overlaps between two users and once a microscope shift ends, users do not need to wait for their data to be transferred. 

Once the image processing pipeline begins \scipionbox will start two independent protocols in parallel. The first protocol estimates the camera gain at each pixel for a few  movies ([**REF coss article][**ROB TODO: this protocol is not in streaming]). In the CNB setup the microscope camera is calibrated and internally performs the gain correction before writing the movies so the estimated gain image should be almost constant and equal to 1. The output of this protocol serves as a verification of the validity of the experimental gain image for the whole data set. The second protocol performs Scipion direct detector movie alignment. Currently \scipionbox offers  four  methods  for  DDD  movie  alignment: motioncorr (Li et al., 2013),
correlation (an unpublished CPU version of the motioncorr method developed in Xmipp),
unblur (Grant and Grigorieff, 2015) and optical flow (Abrishami et al., 2015). Within \scipionbox, movie frames can be aligned using any one of these approaches or any combination. Following the standard processing workflow, the resulting micrographs are screened to eliminate those with excessive astigmatism or drift. Scipion provides three CTF estimation methods:
CTFFIND (Rohou and Grigorieff, 2015), gCTF (Zhang, 2016) and Xmipp CTF estimation (Sorzano et al., 2007; Vargas et al., 2013). At this point the user may compute the CTFs using several algorithms and compare them with the protocol \protocol{CTF consensus} that report up to which frequency two estimation of the same micrograph are equivalent. Further automatic filtering based on CTF is available through the protocol \protocol{CTF filtering} that selects micrographs based on the astigmatism, resolution and defocus. Another criteria for CTF selection is iciness, that is,  the ratio of the intensity in the resolution band between 3.5 and 3.9 \AA, and between 80 and 30 \AA, which gives a good estimate of the ice crystal content of the vitreous specimen.

[**ROB TODO: I have not added the average protocol since I do not know exactly what it does, if somebody wants to contribute here go ahead]

Up to this point the image processing pipeline is quite solid and may be executed in streaming without user intervention. Now, it is time to select (pick) particles. We have recently ported the eight different options available at \scipion  to streaming (see XXXX for details[**delarosa up to which point this is true]). In this way,  particles may be selected as soon as any new micrograph is available. We notice here that some of the ported algorithms require a training step in which either user intervention or information from a previous selection is need. For those users that execute several picking algorithms, the protocol \protocol{picking consensus} may be useful. \protocol{picking consensus}  calculates the agreement between different particle-picking algorithms and produces a list with the particle selected by most of them. [**ROB this algorithm is not in streaming yet, volunteers?]

Two new protocols are under development and will join the described  pipeline in a near future. The first one will perform 2D classification and the second one will create a initial 3D map based on this classes. \scipion currently implements such protocols but the implementation is not adequate for real time processing.

As commented in section \ref{overall}, to complement the streaming process we have developed a set of monitors and report possibilities. By default \protocol{system}, \protocol{CTF} and \protocol{report} monitors are executed. \protocol{System} monitor reports on  CPU and GPU utilization, memory consumption and disk I/O [**ROB TODO: last one to be done]. \protocol{CTF} monitor plots the CTF defocus and astigmatism  and it will raise an alarm if these parameters are not within a given range. Finally the \protocol{report} protocol pushes all the created plots and summaries to a web server 
so this information can be accessed from outside.

The proposed pipeline offers quite flexibility to decide which particular algorithms will be used by a given user. At CNB (and collaborating institutions) we collect protocol usage statistics and sort the different algorithms by popularity.  This information is available at  \url{http://calm-shelf-73264.herokuapp.com/report_protocols/protocolTable/} and may help users to select   between the different algorithms.
